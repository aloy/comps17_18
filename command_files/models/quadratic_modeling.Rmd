---
title: "Quadratic_Modeling"
author: "Sophie Gunn"
date: "February 21, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(MASS)
library(tidyverse)
library(class)
library(randomForest)
library(tidyr)
library(scagnostics)
library(caret)
library(boot)
library(e1071)
```

DATA
```{r}
data <- read_csv("simulation_data/quad_scagnostics.csv")
data <- data[,-1]
names(data)[3:11] <- c("scag_num_1", "scag_num_2", "scag_num_3", "scag_num_4", "scag_num_5", "scag_num_6", "scag_num_7", "scag_num_8", "scag_num_9")
names(data)
info <- read_csv("simulation_data/quad_info.csv")
info <- info[,-1]

```

RANDOM FOREST
```{r}
forestModel <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, ntree=100, importance =T)

forestModel

#choose # of trees where it flattens out?
plot(forestModel)

#cross-validation
predictors <- names(data)
predictors <- predictors[!predictors %in% c("ID","signal")]
cv1 <- rfcv(data[,predictors], data$signal, cv.fold = 10)
cv1$error.cv
```

trying out bagging:
```{r}
forestModel <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, ntree=100, importance =T, mtre = 3)
mean(forestModel$oob.times)
importance(forestModel)

varImpPlot(forestModel)
data <- data %>% mutate( prediction = predict(forestModel, type="response"), 
                 probs = predict(forestModel, type="prob")[,2])

mid_prob <- data %>% filter(probs > 0.3 & probs < 0.7)  %>% select(ID, signal, prediction, probs)

misplaced <- data %>% filter(prediction != signal) %>% left_join(info) %>% mutate(ratio = abs(sd/b)) %>% select(ID, signal, prediction, probs, N, a, b, sd, ratio)

info <- info %>% mutate(ratio = abs(sd/b) )
data %>% left_join(info) %>% group_by(prediction, signal, N) %>% summarize(mean_ratio = mean(ratio), n = n())

predict_analysis <- data %>% 
  mutate( prediction = predict(forestModel, type="response")) %>% 
  group_by(signal, prediction) %>% 
  summarize( n = n(), mean_scag_num_1 = mean(scag_num_1), mean_scag_num_2 = mean(scag_num_2),mean_scag_num_3 = mean(scag_num_3), mean_scag_num_4 = mean(scag_num_4), mean_scag_num_5 = mean(scag_num_5), mean_scag_num_6 = mean(scag_num_6), mean_scag_num_7 = mean(scag_num_7), mean_scag_num_8 = mean(scag_num_8), mean_scag_num_9 = mean(scag_num_9))

importance(forestModel)
```




```{r}
plots <- read.csv('/Users/sophiegunn/Desktop/SchoolWork/winter/comps/toobig/quad_plots.csv')
misplaced_plots <- plots %>% filter(ID %in% misplaced$ID) 

misplaced_plots %>% filter(ID == misplaced$ID[6]) %>% ggplot(aes (x = x, y = y)) + geom_point()

#very bad, why prob of 0?
misplaced_plots %>% filter(ID == 4025) %>% ggplot(aes (x = x, y = y)) + geom_point()

#curious about which one predicted signal but didn't have any:

misplaced_plots %>% filter(ID == 12632) %>% ggplot(aes (x = x, y = y)) + geom_point()
misplaced_plots %>% filter(ID == 6855) %>% ggplot(aes (x = x, y = y)) + geom_point()
misplaced_plots %>% filter(ID == 1735) %>% ggplot(aes (x = x, y = y)) + geom_point()



#okay what about increasing threshold above 50%?
treeModel1 <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, ntree=100, importance =T, mtre = 3, cutoff = c(0.55, 0.45))
treeModel1
forestModel


```

LOGISTIC REGRESSION:
```{r}
glmScag <- glm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, family = "binomial")

summary(glmScag)

glm.probs <- predict(glmScag,type="response")

data$predictions <- ifelse(glm.probs < .5, 0, 1)
mean(data$signal == data$predictions)

#cross validation
1-cv.glm(data, glmScag, K=10)$delta[1]

glmScag1 <- glm(signal ~ scag_num_1+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, family = "binomial")
summary(glmScag1)
anova(glmScag1, test = "Chisq")
anova(glmScag1, glmScag, test = "Chisq")
#plot(glmScag1)

glmScag2 <- glm(signal ~ scag_num_3, data = data, family = "binomial")
summary(glmScag2)
anova(glmScag2, glmScag, test = "Chisq")
```

K Nearest Neighbors
```{r}
train_ind <- sample(seq_len(nrow(data)), size = 16000)
train <- data[train_ind, ]
test <- data[-train_ind, ] 

quad_knn <-  knn(train, test, cl= data$signal[train_ind], k=3)

test <- data_frame(y=data$signal[-train_ind],prediction = quad_knn)

test %>% summarize(accuracy = mean(prediction == y), sensitivity = sum(prediction == 1 & y == 1)/sum(y == 1), specificity = sum(prediction == 0 & y == 0)/sum(y == 0))

quad_knn.cv <- knn.cv(data, cl= data$signal, k=10)
test <- data_frame(y=data$signal[-train_ind],prediction = quad_knn.cv)

test %>% summarize(accuracy = mean(prediction == y),   sensitivity = sum(prediction == 1 & y == 1)/sum(y == 1), specificity = sum(prediction == 0 & y == 0)/sum(y == 0))
```
somehow perfect?

LDA-QDA
```{r}
k <- 5
folds <- cut(sample(seq_len(nrow(data))),  breaks=k, labels=FALSE) 
lda_cv_accuracy <- data.frame(accuracy=numeric(5), stringsAsFactors = FALSE)

for (i in seq_len(k)) {
  train_data <- filter(data, folds != i) 
  test_data <- filter(data, folds == i)

  model_LDA <- lda(train_data$signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)

  predictions_LDA <- data.frame(predict(model_LDA, test_data))
  predictions_LDA <- cbind(test_data, predictions_LDA)
  lda_cv_accuracy[i] <- mean(predictions_LDA$class == predictions_LDA$signal)
}
print(paste("Average Accuracy", mean(lda_cv_accuracy$accuracy)))


#####
#QDA Models
#####

k <- 5
folds <- cut(sample(seq_len(nrow(data))),  breaks=k, labels=FALSE) 
qda1_cv_accuracy <- data.frame(accuracy=numeric(5), stringsAsFactors = FALSE)

for (i in seq_len(k)) {
  train_data <- filter(data, folds != i) 
  test_data <- filter(data, folds == i)

  model_QDA1 <- qda(train_data$signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)


  predictions_QDA1 <- data.frame(predict(model_QDA1, test_data))
  predictions_QDA1 <- cbind(test_data, predictions_QDA1)
  qda1_cv_accuracy[i] <- mean(predictions_QDA1$class == predictions_QDA1$signal)
}
print(paste("Average Accuracy", mean(qda1_cv_accuracy$accuracy)))

#QDA using only monotonic as a predictor
k <- 5
folds <- cut(sample(seq_len(nrow(data))),  breaks=k, labels=FALSE) 
qda2_cv_accuracy <- data.frame(accuracy=numeric(5), stringsAsFactors = FALSE)

for (i in seq_len(k)) {
  train_data <- filter(data, folds != i) 
  test_data <- filter(data, folds == i)

  model_QDA2 <- qda(train_data$signal~scag_num_9, data = train_data)


  predictions_QDA2 <- data.frame(predict(model_QDA2, test_data))
  predictions_QDA2 <- cbind(test_data, predictions_QDA2)
  qda2_cv_accuracy[i] <- mean(predictions_QDA2$class == predictions_QDA2$signal)
}
print(paste("Average Accuracy", mean(qda2_cv_accuracy$accuracy)))
```

SVM
```{r}
quad_svm <- tune.svm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = data, cost = c(0.5, 0.6, 0.7, 0.8), tunecontrol=tune.control(cross=10))

summary(quad_svm)
svm.probs <- predict(quad_svm$best.model,type="response")
plot(svm.probs)
summary(svm.probs)

train_ind <- sample(seq_len(nrow(data)), size = 16000)
train <- data[train_ind, ]
test <- data[-train_ind, ] 

summary(quad_svm)

quad_svm_simple <- svm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train, probability = T)

summary(quad_svm_simple )
new <- predict(quad_svm_simple, test, decision.values = TRUE, probability = TRUE)

svm.probs <- predict(quad_svm_simple,type="response")
data$svm.probs <- predict(quad_svm_simple,type="response")
test$svm.preds <- ifelse(new < .5, 0, 1)
mean(test$signal == test$svm.preds)
summary(quad_svm_simple)

```


following lab!
```{r}
set.seed(1)
tune.out <- tune.svm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data=data , cost=c(0.001, 0.01, 0.1, 1,5,10,100) )


```