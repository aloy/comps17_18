---
title: "MTurk_Lineups"
author: "Aidan Mullan"
date: "3/8/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(nullabor)
library(ggplot2)
library(dplyr)
library(scagnostics)
library(MASS)
library(tidyverse)
library(caret)
library(randomForest)

scagnostics <- read.csv("simulation_data/all_turk_scagnostics.csv")
scagnostics <- scagnostics[,-1]
info <- read.csv("simulation_data/all_turk_info.csv")
info <- info[,-1]
colnames(info) <- c("lineup", "lineup.ID", "ID", "n", "df", "signal", "seed")
plots <- read.csv("simulation_data/all_turk_plots.csv")
plots <- plots[,-1]

scagnostics$lineup <- info$lineup
```


```{r}
#Lineups with 19 simulated noise and 1 simulated signal
sample <- sample_n(info, 1)
lineup_plots <- subset(plots, plots$lineup == sample$lineup)
lineup_info <- subset(info, info$lineup == sample$lineup)
signal_info <- lineup_info[which(lineup_info$signal == 1),]


#To scale all plots, scales = "free" in facet_wrap
ggplot(lineup_plots, aes(x, y)) +
  geom_point() +
  facet_wrap(~lineup.ID, nrow = 4, labeller = label_context) 


cat("Different Plot:", signal_info$lineup.ID)
```

```{r, warning=FALSE}
#####
#Lineups with distance predictions
#####

lineup_scagnostics <- subset(scagnostics, scagnostics$ID %in% lineup_info$ID)
dscags <- lineup_scagnostics[,c(2:8,10)]
means <- colMeans(dscags)

#Euclidean distance
eu_dists <- NULL
for (i in 1:20){
  eu_dists <- c(eu_dists, (dist(rbind(dscags[i,],means))))
}
cat("Euclidean:", which(eu_dists == max(eu_dists)))

#Mahalnobis distance
mah_dists <- mahalanobis(dscags, means, cov(dscags))
cat("\nMahalnobis:", which(mah_dists == max(mah_dists)))

#####
#Lineups with model predictions
#####

lineup_scagnostics <- arrange(lineup_scagnostics, ID)
index = which(scagnostics$ID %in% lineup_scagnostics$ID)
train_data <- scagnostics[-index,]

#LDA
model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
QDA_preds <- predict(model_QDA, lineup_scagnostics, type = "response")
cat("\nLDA:", which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2])))

#Logistic
model_logit <- glm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data, family = "binomial")
logit_preds <- predict(model_logit, lineup_scagnostics, type = "response")
cat("\nLogitsic:", which(logit_preds == max(logit_preds)))
```

Testing prediction accuracy
```{r, warning = FALSE}
Rep = 10
R = 1000
choices2 <- data.frame(correct.choice = numeric(R*Rep), eu.choice = numeric(R*Rep), maha.choice = numeric(R*Rep), rf.choice = numeric(R*Rep), knn.choice = numeric(R*Rep), lda.choice = numeric(R*Rep), logit.choice = numeric(R*Rep))
for(rep in 1:Rep){
  print(rep)
  train_index <- sample(48, 24)
  train_data <- subset(scagnostics, scagnostics$lineup %in% train_index)
  index = which(scagnostics$ID %in% train_data$ID)
  test_data <- scagnostics[-index,]


  model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, family ="binomial")
  control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  model_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
  model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data,
                           ntree=100, importance =T)




  for(r in 1:R){
    if (r%%100 == 0){print(r)}
    entry <- ((rep-1)*R)+r
    sample_lineup <- sample(test_data$lineup, 1)
    lineup_scagnostics <- subset(test_data, test_data$lineup == sample_lineup)
    lineup_scagnostics <- arrange(lineup_scagnostics, ID)
    choices2$correct.choice[entry] <- which(lineup_scagnostics$signal == 1)
  
    dscags <- lineup_scagnostics[,c(2:8, 10)]
    means <- colMeans(dscags)
    eu_dists <- NULL
    for (i in 1:20){
      eu_dists <- c(eu_dists, (dist(rbind(dscags[i,],means))))
    }
    choices2$eu.choice[entry] <- which(eu_dists == max(eu_dists))
  
    mah_dists <- mahalanobis(dscags, means, cov(dscags))
    choices2$maha.choice[entry] <- which(mah_dists == max(mah_dists))
  
    index = which(combined$ID %in% lineup_scagnostics$ID)
    train_data <- combined[-index,]
  
    LDA_preds <- predict(model_LDA, lineup_scagnostics, type = "response")
    choices2$lda.choice[entry] <- which(LDA_preds$posterior[,2] == max(LDA_preds$posterior[,2]))

    logit_preds <- predict(model_logit, lineup_scagnostics, type = "response")
    choices2$logit.choice[entry] <- which(logit_preds == max(logit_preds))
  
    knn_preds <- predict.train(model_knn, lineup_scagnostics, type = "prob")
    choices2$knn.choice[entry] <- which(knn_preds[,2] == max(knn_preds[,2]))

    rf_preds <- predict(model_rf, newdata = lineup_scagnostics[,2:10], type = "prob")
    choices2$rf.choice[entry] <- which(rf_preds[,2] == max(rf_preds[,2]))  

  
  }
}
accuracy2 <- data.frame(Euclidean = mean(choices2$eu.choice == choices2$correct.choice), 
                       Mahalanobis = mean(choices2$maha.choice == choices2$correct.choice),
                       LDA = mean(choices2$lda.choice == choices2$correct.choice),
                       Logistic = mean(choices2$logit.choice == choices2$correct.choice),
                       KNN = mean(choices2$knn.choice == choices2$correct.choice),
                       Random.Forest = mean(choices2$rf.choice == choices2$correct.choice))
accuracy2
#EU - .077, MAH - .000, QDA - .067, LOG - .062, KNN - .038, RF - .040
```



