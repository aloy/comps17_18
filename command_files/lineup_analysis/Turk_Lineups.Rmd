---
title: "MTurk_Lineups"
author: "Aidan Mullan"
date: "3/8/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(nullabor)
library(ggplot2)
library(dplyr)
library(scagnostics)
library(MASS)
library(tidyverse)
library(caret)
library(randomForest)

scagnostics <- read.csv("simulation_data/all_turk_scagnostics.csv")
scagnostics <- scagnostics[,-1]
info <- read.csv("simulation_data/all_turk_info.csv")
info <- info[,-1]
colnames(info) <- c("lineup", "lineup.ID", "ID", "n", "df", "signal", "seed")
plots <- read.csv("simulation_data/all_turk_plots.csv")
plots <- plots[,-1]

scagnostics$lineup <- info$lineup
```


```{r}
#Lineups with 19 simulated noise and 1 simulated signal
sample <- sample_n(info, 1)
lineup_plots <- subset(plots, plots$lineup == sample$lineup)
lineup_info <- subset(info, info$lineup == sample$lineup)
signal_info <- lineup_info[which(lineup_info$signal == 1),]


#To scale all plots, scales = "free" in facet_wrap
ggplot(lineup_plots, aes(x, y)) +
  geom_point() +
  facet_wrap(~lineup.ID, nrow = 4, labeller = label_context) 


cat("Different Plot:", signal_info$lineup.ID)
```

```{r, warning=FALSE}
#####
#Lineups with distance predictions
#####

lineup_scagnostics <- subset(scagnostics, scagnostics$ID %in% lineup_info$ID)
dscags <- lineup_scagnostics[,c(2:8,10)]
means <- colMeans(dscags)

#Euclidean distance
eu_dists <- NULL
for (i in 1:20){
  eu_dists <- c(eu_dists, (dist(rbind(dscags[i,],means))))
}
cat("Euclidean:", which(eu_dists == max(eu_dists)))

#Mahalnobis distance
mah_dists <- mahalanobis(dscags, means, cov(dscags))
cat("\nMahalnobis:", which(mah_dists == max(mah_dists)))

#####
#Lineups with model predictions
#####

lineup_scagnostics <- arrange(lineup_scagnostics, ID)
index = which(scagnostics$ID %in% lineup_scagnostics$ID)
train_data <- scagnostics[-index,]

#LDA
model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
QDA_preds <- predict(model_QDA, lineup_scagnostics, type = "response")
cat("\nLDA:", which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2])))

#Logistic
model_logit <- glm(signal ~ scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data, family = "binomial")
logit_preds <- predict(model_logit, lineup_scagnostics, type = "response")
cat("\nLogitsic:", which(logit_preds == max(logit_preds)))
```

Testing prediction accuracy
```{r, warning = FALSE}
choices2 <- data.frame(correct.choice = numeric(48), eu.choice = numeric(48), maha.choice = numeric(48), rf.choice = numeric(48), knn.choice = numeric(48), lda.choice = numeric(48), logit.choice = numeric(48))
for(i in 1:48){
  print(i)
  test_data <- subset(scagnostics, scagnostics$lineup == i)
  train_data <- subset(scagnostics, scagnostics$lineup != i)
  choices2$correct.choice[i] <- which(test_data$signal == 1)

  model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_9, data = train_data)
  LDA_preds <- predict(model_LDA, test_data, type = "response")
  choices2$lda.choice[i] <- which(LDA_preds$posterior[,2] == max(LDA_preds$posterior[,2]))
  
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_9, 
                     data = train_data, family ="binomial")
  logit_preds <- predict(model_logit, test_data, type = "response")
  choices2$logit.choice[i] <- which(logit_preds == max(logit_preds))
  
  control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  model_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_9, 
                     data = train_data, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
  knn_preds <- predict.train(model_knn, test_data, type = "prob")
  choices2$knn.choice[i] <- which(knn_preds[,2] == max(knn_preds[,2]))
  
  model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_9, data = train_data,
                           ntree=100, importance =T)
  rf_preds <- predict(model_rf, newdata = test_data[,c(2:8,10)], type = "prob")
  choices2$rf.choice[i] <- which(rf_preds[,2] == max(rf_preds[,2]))  
  
  dscags <- test_data[,c(2:8, 10)]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  choices2$eu.choice[i] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices2$maha.choice[i] <- which(mah_dists == max(mah_dists))
}

accuracy2 <- data.frame(Euclidean = mean(choices2$eu.choice == choices2$correct.choice), 
                       Mahalanobis = mean(choices2$maha.choice == choices2$correct.choice),
                       LDA = mean(choices2$lda.choice == choices2$correct.choice),
                       Logistic = mean(choices2$logit.choice == choices2$correct.choice),
                       KNN = mean(choices2$knn.choice == choices2$correct.choice),
                       Random.Forest = mean(choices2$rf.choice == choices2$correct.choice))
accuracy2
#EU - .083, MAH - .000, QDA - .000, LOG - .000, KNN - .021, RF - .083
#Random chance suggests an accuracy of .050
```



