---
title: "Combined_Lineups"
author: "Aidan Mullan"
date: "3/3/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(nullabor)
library(ggplot2)
library(dplyr)
library(scagnostics)
library(MASS)
library(tidyverse)

combined <- read.csv("simulation_data/combined_scagnostics.csv")
signal <- subset(combined, combined$signal == 1)
null <- subset(combined, combined$signal == 0)
```

```{r}
signal_scagnostics <- sample_n(signal, 1)
null_scagnostics <- sample_n(null, 19)
lineup_scagnostics <- rbind(signal_scagnostics, null_scagnostics)
cat("Different Plot:", lineup_scagnostics$ID[1])

lineup_scagnostics <- arrange(lineup_scagnostics, ID)
```

```{r}
#####
#Leave One Out Predictions
#####
loo.euclid <- numeric(20)
loo.maha <- numeric(20)
dscags <- lineup_scagnostics[,4:12]
for(index in 1:20){
  means = colMeans(dscags[-index,])
  loo.euclid[index] <- dist(rbind(dscags[index,], means))
  loo.maha[index] <- mahalanobis(dscags[index,], means, cov(dscags[-index,]))
}
cat("LOO Euclidean:", which(loo.euclid == max(loo.euclid)))
cat("\nLOO Mahalanobis:", which(loo.maha == max(loo.maha)))
```


```{r, warning = FALSE}
#####
#Testing all Prediction Methods
#####
R = 1000
choices <- data.frame(correct.choice = numeric(R), eu.choice = numeric(R), maha.choice = numeric(R), qda.choice = numeric(R), logit.choice = numeric(R), knn.choice = numeric(R), rf.choice = numeric(R))

for(r in 1:R){
  if (r%%100 == 0){print(r)}
  signal_scagnostics <- sample_n(signal, 1)
  null_scagnostics <- sample_n(null, 19)
  lineup_scagnostics <- rbind(signal_scagnostics, null_scagnostics)
  lineup_scagnostics <- arrange(lineup_scagnostics, ID)
  choices$correct.choice[r] <- which(lineup_scagnostics$ID == signal_scagnostics$ID)
  
  dscags <- lineup_scagnostics[,4:12]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (i in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[i,],means))))
  }
  choices$eu.choice[r] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices$maha.choice[r] <- which(mah_dists == max(mah_dists))
  
  index = which(combined$ID %in% lineup_scagnostics$ID)
  train_data <- combined[-index,]
  model_QDA <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  QDA_preds <- predict(model_QDA, lineup_scagnostics, type = "response")
  choices$qda.choice[r] <- which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2]))
  
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data, family ="binomial")
  logit_preds <- predict(model_logit, lineup_scagnostics, type = "response")
  choices$logit.choice[r] <- which(logit_preds == max(logit_preds))
  
  #control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  #model_knn <- train(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
   #                  scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
    #                 data = train_data, method = "knn", trControl = control)
  #knn_preds <- predict.train(model_knn, lineup_scagnostics)
  #choices$knn.choice[r] <- which(knn_preds == max(knn_preds))
  
  #model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
   #                          scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data,
    #                       ntree=100, importance =T)
  #rf_preds <- predict(model_rf, newdata = lineup_scagnostics[,4:12], type = "prob")
  #choices$rf.choice[r] <- which(rf_preds[,2] == max(rf_preds[,2]))
  #KNN AND RF ARE COMPUTATIONALLY INTENSIVE: ~1HR FOR 50 ITERATIONS
}
accuracy <- data.frame(Euclidean = mean(choices$eu.choice == choices$correct.choice), 
                       Mahalanobis = mean(choices$maha.choice == choices$correct.choice),
                       QDA = mean(choices$qda.choice == choices$correct.choice),
                       Logistic = mean(choices$logit.choice == choices$correct.choice),
                       K.Nearest.Neighbors = mean(choices$knn.choice == choices$correct.choice),
                       Random.Forest = mean(choices$rf.choice == choices$correct.choice))
accuracy
#EU - .770, MA - .952, QDA - .965, LOG - .972, LEU - .770, LMA - .952, KNN - , RF - 
```


Just comparing LOO Euclidean and Maha
```{r}
R = 5000
choices1 <- data.frame(correct.choice = numeric(R), eu.choice = numeric(R), maha.choice = numeric(R), loo.euclid = numeric(R), loo.maha = numeric(R), rf.choice = numeric(R), knn.choice = numeric(R))

for(r in 1:R){
  if (r%%500 == 0){print(r)}
  signal_scagnostics <- sample_n(signal, 1)
  null_scagnostics <- sample_n(null, 19)
  lineup_scagnostics <- rbind(signal_scagnostics, null_scagnostics)
  lineup_scagnostics <- arrange(lineup_scagnostics, ID)
  choices1$correct.choice[r] <- which(lineup_scagnostics$ID == signal_scagnostics$ID)
  
  dscags <- lineup_scagnostics[,4:12]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (i in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[i,],means))))
  }
  choices1$eu.choice[r] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices1$maha.choice[r] <- which(mah_dists == max(mah_dists))
  
  loo.euclid <- numeric(20)
  loo.maha <- numeric(20)
  for(index in 1:20){
    means = colMeans(dscags[-index,])
    loo.euclid[index] <- dist(rbind(dscags[index,], means))
    loo.maha[index] <- mahalanobis(dscags[index,], means, cov(dscags[-index,]))
  }
  choices1$loo.euclid[r] <- which(loo.euclid == max(loo.euclid))
  choices1$loo.maha[r] <- which(loo.maha == max(loo.maha))
  

  
}
accuracy <- data.frame(Euclidean = mean(choices1$eu.choice == choices1$correct.choice), 
                       Mahalanobis = mean(choices1$maha.choice == choices1$correct.choice),
                       LOO.Euclidean = mean(choices1$loo.euclid == choices1$correct.choice),
                       LOO.Mahalanobis = mean(choices1$loo.maha == choices1$correct.choice))
accuracy

```

IDEAS:
-Add in knn and random forest predictions
-Test lineups with datasets not in combined
-Test multiple signal plots

