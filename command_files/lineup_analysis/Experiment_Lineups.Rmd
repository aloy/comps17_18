---
title: "Experiment Lineups"
author: "Aidan Mullan"
date: "4/16/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(nullabor)
library(ggplot2)
library(dplyr)
library(scagnostics)
library(MASS)
library(caret)
library(randomForest)

scagnostics <- read.csv("for_study/experiment_scagnostics.csv")
scagnostics2 <- scagnostics[,c(4:13,15)]


signal <- subset(scagnostics, scagnostics$signal == 1)
null <- subset(scagnostics, scagnostics$signal == 0)
```

```{r}
#Predictions with unknown n
K <- 18
choices <- data.frame(correct.choice = numeric(K), lda.choice = numeric(K), qda.choice = numeric(K), logit.choice = numeric(K), knn.choice = numeric(K), rf.choice = numeric(K), eu.choice = numeric(K), maha.choice = numeric(K))

for(i in 1:K){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  train_data <- subset(scagnostics2, scagnostics2$lineup != i)
  choices$correct.choice[i] <- list(which(test_data$signal == 1))
  n <- length(subset(test_data$signal, test_data$signal == 1))

  model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  LDA_preds <- predict(model_LDA, test_data, type = "response")
  LDA_max <- sort(LDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$lda.choice[i] <- list(which(LDA_preds$posterior[,2] %in% LDA_max))
  
  model_QDA <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  QDA_preds <- predict(model_QDA, test_data, type = "response")
  QDA_max <- sort(QDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$qda.choice[i] <- list(which(QDA_preds$posterior[,2] %in% QDA_max))
  
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, family ="binomial")
  logit_preds <- predict(model_logit, test_data, type = "response")
  logit_max <- sort(logit_preds, decreasing = TRUE)[1:n]
  choices$logit.choice[i] <- list(which(logit_preds %in% logit_max))
  
  control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  model_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
  knn_preds <- predict.train(model_knn, test_data, type = "prob")
  knn_max <- sort(knn_preds[,2], decreasing = TRUE)[1:n]
  choices$knn.choice[i] <- list(which(knn_preds[,2] %in% knn_max))
  
  model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data,
                           ntree=100, importance =T)
  rf_preds <- predict(model_rf, newdata = test_data[,1:9], type = "prob")
  rf_max <- sort(rf_preds[,2], decreasing = TRUE)[1:n]
  choices$rf.choice[i] <- list(which(rf_preds[,2] %in% rf_max)) 
  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  eu_max <- sort(eu_dists, decreasing = TRUE)[1:n]
  choices$eu.choice[i] <- list(which(eu_dists %in% eu_max))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  mah_max <- sort(mah_dists, decreasing = TRUE)[1:n]
  choices$maha.choice[i] <- list(which(mah_dists %in% mah_max))
}

accuracy <- data.frame(Euclidean = numeric(K), Mahalanobis = numeric(K), LDA = numeric(K), QDA = numeric(K), Logistic = numeric(K), KNN = numeric(K), Random.Forest = numeric(K))

for(set in 1:K){
  correct <- choices$correct.choice[[set]]
  len <- length(correct)
  eu.acc <- sum(choices$eu.choice[[set]] %in% correct)/len
  accuracy$Euclidean[set] <- ifelse(is.na(eu.acc), 0, eu.acc)
  mah.acc <- sum(choices$maha.choice[[set]] %in% correct)/len
  accuracy$Mahalanobis[set] <- ifelse(is.na(mah.acc), 0, mah.acc)
  lda.acc <- sum(choices$lda.choice[[set]] %in% correct)/len
  accuracy$LDA[set] <- ifelse(is.na(lda.acc), 0, lda.acc)
  qda.acc <- sum(choices$qda.choice[[set]] %in% correct)/len
  accuracy$QDA[set] <- ifelse(is.na(qda.acc), 0, qda.acc)
  log.acc <- sum(choices$logit.choice[[set]] %in% correct)/len
  accuracy$Logistic[set] <- ifelse(is.na(log.acc), 0, log.acc)
  knn.acc  <- sum(choices$knn.choice[[set]] %in% correct)/len
  accuracy$KNN[set] <- ifelse(is.na(knn.acc), 0, knn.acc)
  rf.acc <- sum(choices$rf.choice[[set]] %in% correct)/len
  accuracy$Random.Forest[set] <- ifelse(is.na(rf.acc), 0, rf.acc)
} 

fp <- data.frame(Euclidean = numeric(K), Mahalanobis = numeric(K), LDA = numeric(K), QDA = numeric(K), Logistic = numeric(K), KNN = numeric(K), Random.Forest = numeric(K))

for(set in 1:K){
  correct <- choices$correct.choice[[set]]
  fp$Euclidean[set] <- 1 - mean(choices$eu.choice[[set]] %in% correct)
  fp$Mahalanobis[set] <- 1 - mean(choices$maha.choice[[set]] %in% correct)
  fp$LDA[set] <- 1 - mean(choices$lda.choice[[set]] %in% correct)
  fp$QDA[set] <- 1 - mean(choices$qda.choice[[set]] %in% correct)
  fp$Logistic[set] <- 1 - mean(choices$logit.choice[[set]] %in% correct)
  fp$KNN[set] <- 1 - mean(choices$knn.choice[[set]] %in% correct)
  fp$Random.Forest[set] <- 1 - mean(choices$rf.choice[[set]] %in% correct)
}    

colMeans(accuracy[c(1:4,7:14),])
colMeans(accuracy[c(5,6,15:18),])
colMeans(fp)
#Acc: EU - .878, MAH - .709, LDA - .861, QDA - .811, LOG - .850, KNN - .972, RF - .917
#FalPo: EU - .122, MAH - .291, LDA - .139, QDA - .189, LOG - .150, KNN - .352, RF - .083
```

```{r}
#1-4, 7-14: 1 choice, 5-6, 15-18: n choices
K <- 18
choices2 <- data.frame(correct.choice = numeric(K), eu.choice = numeric(K), maha.choice = numeric(K), rf.choice = numeric(K), knn.choice = numeric(K), lda.choice = numeric(K), qda.choice = numeric(K), logit.choice = numeric(K))
for(i in c(1:4,7:14)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  train_data <- subset(scagnostics2, scagnostics2$lineup != i)
  choices2$correct.choice[i] <- which(test_data$signal == 1)

  model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  LDA_preds <- predict(model_LDA, test_data, type = "response")
  choices2$lda.choice[i] <- which(LDA_preds$posterior[,2] == max(LDA_preds$posterior[,2]))
  
  model_QDA <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  QDA_preds <- predict(model_QDA, test_data, type = "response")
  choices2$qda.choice[i] <- which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2]))
  
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, family ="binomial")
  logit_preds <- predict(model_logit, test_data, type = "response")
  choices2$logit.choice[i] <- which(logit_preds == max(logit_preds))
  
  control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  model_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
  knn_preds <- predict.train(model_knn, test_data, type = "prob")
  choices2$knn.choice[i] <- which(knn_preds[,2] == max(knn_preds[,2]))
  
  model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data,
                           ntree=100, importance =T)
  rf_preds <- predict(model_rf, newdata = test_data[,1:9], type = "prob")
  choices2$rf.choice[i] <- which(rf_preds[,2] == max(rf_preds[,2]))  
  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  choices2$eu.choice[i] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices2$maha.choice[i] <- which(mah_dists == max(mah_dists))
}

for(i in c(5,6,15:18)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  train_data <- subset(scagnostics2, scagnostics2$lineup != i)
  choices2$correct.choice[i] <- list(which(test_data$signal == 1))
  n <- length(subset(test_data$signal, test_data$signal == 1))

  model_LDA <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  LDA_preds <- predict(model_LDA, test_data, type = "response")
  choices2$lda.choice[i] <- list(which(LDA_preds$posterior[,2] > 0.5))
  
  model_QDA <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data)
  QDA_preds <- predict(model_QDA, test_data, type = "response")
  choices2$qda.choice[i] <- list(which(QDA_preds$posterior[,2] > 0.5))
  
  model_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, family ="binomial")
  logit_preds <- predict(model_logit, test_data, type = "response")
  choices2$logit.choice[i] <- list(which(logit_preds > 0.5))
  
  control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
  model_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = train_data, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
  knn_preds <- predict.train(model_knn, test_data, type = "prob")
  choices2$knn.choice[i] <- list(which(knn_preds[,2] > 0.5))
  
  model_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = train_data,
                           ntree=100, importance =T)
  rf_preds <- predict(model_rf, newdata = test_data[,1:9], type = "prob")
  choices2$rf.choice[i] <- list(which(rf_preds[,2] > 0.5)) 
  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  eu_max <- sort(eu_dists, decreasing = TRUE)[1:n]
  choices2$eu.choice[i] <- list(which(eu_dists %in% eu_max))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  mah_max <- sort(mah_dists, decreasing = TRUE)[1:n]
  choices2$maha.choice[i] <- list(which(mah_dists %in% mah_max))
}

choices2[18,6:8] <- 0
accuracy2 <- data.frame(Euclidean = numeric(K), Mahalanobis = numeric(K), LDA = numeric(K), QDA = numeric(K), Logistic = numeric(K), KNN = numeric(K), Random.Forest = numeric(K))

for(set in 1:K){
  correct <- choices2$correct.choice[[set]]
  len <- length(correct)
  eu.acc <- sum(choices2$eu.choice[[set]] %in% correct)/len
  accuracy2$Euclidean[set] <- ifelse(is.na(eu.acc), 0, eu.acc)
  mah.acc <- sum(choices2$maha.choice[[set]] %in% correct)/len
  accuracy2$Mahalanobis[set] <- ifelse(is.na(mah.acc), 0, mah.acc)
  lda.acc <- sum(choices2$lda.choice[[set]] %in% correct)/len
  accuracy2$LDA[set] <- ifelse(is.na(lda.acc), 0, lda.acc)
  qda.acc <- sum(choices2$qda.choice[[set]] %in% correct)/len
  accuracy2$QDA[set] <- ifelse(is.na(qda.acc), 0, qda.acc)
  log.acc <- sum(choices2$logit.choice[[set]] %in% correct)/len
  accuracy2$Logistic[set] <- ifelse(is.na(log.acc), 0, log.acc)
  knn.acc  <- sum(choices2$knn.choice[[set]] %in% correct)/len
  accuracy2$KNN[set] <- ifelse(is.na(knn.acc), 0, knn.acc)
  rf.acc <- sum(choices2$rf.choice[[set]] %in% correct)/len
  accuracy2$Random.Forest[set] <- ifelse(is.na(rf.acc), 0, rf.acc)
} 

fp2 <- data.frame(Euclidean = numeric(K), Mahalanobis = numeric(K), LDA = numeric(K), QDA = numeric(K), Logistic = numeric(K), KNN = numeric(K), Random.Forest = numeric(K))

for(set in 1:K){
  correct <- choices2$correct.choice[[set]]
  fp2$Euclidean[set] <- 1 - mean(choices2$eu.choice[[set]] %in% correct)
  fp2$Mahalanobis[set] <- 1 - mean(choices2$maha.choice[[set]] %in% correct)
  fp2$LDA[set] <- 1 - mean(choices2$lda.choice[[set]] %in% correct)
  fp2$QDA[set] <- 1 - mean(choices2$qda.choice[[set]] %in% correct)
  fp2$Logistic[set] <- 1 - mean(choices2$logit.choice[[set]] %in% correct)
  fp2$KNN[set] <- 1 - mean(choices2$knn.choice[[set]] %in% correct)
  fp2$Random.Forest[set] <- 1 - mean(choices2$rf.choice[[set]] %in% correct)
}  

colMeans(accuracy2)
colMeans(fp2)
#Acc: EU - .878, MAH - .709, LDA - .781, QDA - .772, LOG - .822, KNN - .654, RF - .883
#FalPo: EU - .122, MAH - .291, LDA - .185, QDA - .185, LOG - .167, KNN - .250, RF - .056
```

These first two prediction sets model signal based solely on the plots included in the experiment lineups. No differentiation was made between the linear and Turk lineups. The next step is to fit models to outside datasets specific to the lineup distribution and re-predict.

```{r}
turk16.scags <- read.csv("simulation_data/turk16_scagnostics.csv")[,-1]
turk18.scags <- read.csv("simulation_data/turk18_scagnostics.csv")[,-c(1,12)]
turk.scags <- rbind(turk16.scags, turk18.scags)

lin.scags <- read.csv("simulation_data/linear2_scagnostics.csv")[,-c(1:2)]
colnames(lin.scags) <- c("ID", "scag_num_1", "scag_num_2", "scag_num_3", "scag_num_4", "scag_num_5", "scag_num_6", "scag_num_7", "scag_num_8", "scag_num_9", "signal")

linear_lda <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags)
linear_qda <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags)
linear_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = lin.scags, family ="binomial")
control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
linear_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = lin.scags, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
linear_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags,
                           ntree=100, importance =T)

turk_lda <- lda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags)
turk_qda <- qda(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                     scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags)
turk_logit <- glm(signal~scag_num_1+scag_num_2+scag_num_3+scag_num_4+scag_num_5+
                       scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = lin.scags, family ="binomial")
control <- trainControl(method = "cv", number = 10, classProbs = TRUE, returnData = TRUE)
turk_knn <- train(make.names(as.factor(signal))~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                       scag_num_5+scag_num_6+scag_num_6+scag_num_7+scag_num_8+scag_num_9, 
                     data = lin.scags, method = "knn", trControl = control, 
                   tuneGrid = expand.grid(k = 1:25))
turk_rf <- randomForest(as.factor(signal) ~scag_num_1+scag_num_2+scag_num_3+scag_num_4+
                             scag_num_5+scag_num_6+scag_num_7+scag_num_8+scag_num_9, data = lin.scags,
                           ntree=100, importance =T)

K <- 18
choices <- data.frame(correct.choice = numeric(K), eu.choice = numeric(K), maha.choice = numeric(K), rf.choice = numeric(K), knn.choice = numeric(K), lda.choice = numeric(K), qda.choice = numeric(K), logit.choice = numeric(K))

for(i in c(1:4)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  choices$correct.choice[i] <- which(test_data$signal == 1)

  LDA_preds <- predict(linear_lda, test_data, type = "response")
  choices$lda.choice[i] <- which(LDA_preds$posterior[,2] == max(LDA_preds$posterior[,2]))
  QDA_preds <- predict(linear_qda, test_data, type = "response")
  choices$qda.choice[i] <- which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2]))
  logit_preds <- predict(linear_logit, test_data, type = "response")
  choices$logit.choice[i] <- which(logit_preds == max(logit_preds))
  knn_preds <- predict.train(linear_knn, test_data, type = "prob")
  choices$knn.choice[i] <- which(knn_preds[,2] == max(knn_preds[,2]))
  rf_preds <- predict(linear_rf, newdata = test_data[,1:9], type = "prob")
  choices$rf.choice[i] <- which(rf_preds[,2] == max(rf_preds[,2]))  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  choices$eu.choice[i] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices$maha.choice[i] <- which(mah_dists == max(mah_dists))
}

for(i in c(7:14)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  choices$correct.choice[i] <- which(test_data$signal == 1)

  LDA_preds <- predict(turk_lda, test_data, type = "response")
  choices$lda.choice[i] <- which(LDA_preds$posterior[,2] == max(LDA_preds$posterior[,2]))
  QDA_preds <- predict(turk_qda, test_data, type = "response")
  choices$qda.choice[i] <- which(QDA_preds$posterior[,2] == max(QDA_preds$posterior[,2]))
  logit_preds <- predict(turk_logit, test_data, type = "response")
  choices$logit.choice[i] <- which(logit_preds == max(logit_preds))
  knn_preds <- predict.train(turk_knn, test_data, type = "prob")
  choices$knn.choice[i] <- which(knn_preds[,2] == max(knn_preds[,2]))
  rf_preds <- predict(turk_rf, newdata = test_data[,1:9], type = "prob")
  choices$rf.choice[i] <- which(rf_preds[,2] == max(rf_preds[,2]))  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  choices$eu.choice[i] <- which(eu_dists == max(eu_dists))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  choices$maha.choice[i] <- which(mah_dists == max(mah_dists))
}

for(i in c(5:6)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  choices$correct.choice[i] <- list(which(test_data$signal == 1))
  n <- length(subset(test_data$signal, test_data$signal == 1))

  LDA_preds <- predict(linear_lda, test_data, type = "response")
  LDA_max <- sort(LDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$lda.choice[i] <- list(which(LDA_preds$posterior[,2] %in% LDA_max))
  
  QDA_preds <- predict(linear_qda, test_data, type = "response")
  QDA_max <- sort(QDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$qda.choice[i] <- list(which(QDA_preds$posterior[,2] %in% QDA_max))
  
  logit_preds <- predict(linear_logit, test_data, type = "response")
  logit_max <- sort(logit_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$logit.choice[i] <- list(which(logit_preds %in% logit_max))
  
  knn_preds <- predict.train(linear_knn, test_data, type = "prob")
  knn_max <- sort(knn_preds[,2], decreasing = TRUE)[1:n]
  choices$knn.choice[i] <- list(which(knn_preds[,2] %in% knn_max))
  
  rf_preds <- predict(linear_rf, newdata = test_data[,1:9], type = "prob")
  rf_max <- sort(rf_preds[,2], decreasing = TRUE)[1:n]
  choices$rf.choice[i] <- list(which(rf_preds[,2] %in% rf_max)) 
  
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  eu_max <- sort(eu_dists, decreasing = TRUE)[1:n]
  choices$eu.choice[i] <- list(which(eu_dists %in% eu_max))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  mah_max <- sort(mah_dists, decreasing = TRUE)[1:n]
  choices$maha.choice[i] <- list(which(mah_dists %in% mah_max))
}

for(i in c(15:18)){
  print(i)
  test_data <- subset(scagnostics2, scagnostics2$lineup == i)
  choices$correct.choice[i] <- list(which(test_data$signal == 1))
  n <- length(subset(test_data$signal, test_data$signal == 1))

  LDA_preds <- predict(turk_lda, test_data, type = "response")
  LDA_max <- sort(LDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$lda.choice[i] <- list(which(LDA_preds$posterior[,2] %in% LDA_max))
  
  QDA_preds <- predict(turk_qda, test_data, type = "response")
  QDA_max <- sort(QDA_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$qda.choice[i] <- list(which(QDA_preds$posterior[,2] %in% QDA_max))
  
  logit_preds <- predict(turk_logit, test_data, type = "response")
  logit_max <- sort(logit_preds$posterior[,2], decreasing = TRUE)[1:n]
  choices$logit.choice[i] <- list(which(logit_preds %in% logit_max))
  
  knn_preds <- predict.train(turk_knn, test_data, type = "prob")
  knn_max <- sort(knn_preds[,2], decreasing = TRUE)[1:n]
  choices$knn.choice[i] <- list(which(knn_preds[,2] %in% knn_max))
  
  rf_preds <- predict(turk_rf, newdata = test_data[,1:9], type = "prob")
  rf_max <- sort(rf_preds[,2], decreasing = TRUE)[1:n]
  choices$rf.choice[i] <- list(which(rf_preds[,2] %in% rf_max)) 
  dscags <- test_data[,1:9]
  means <- colMeans(dscags)
  eu_dists <- NULL
  for (j in 1:20){
    eu_dists <- c(eu_dists, (dist(rbind(dscags[j,],means))))
  }
  eu_max <- sort(eu_dists, decreasing = TRUE)[1:n]
  choices$eu.choice[i] <- list(which(eu_dists %in% eu_max))
  
  mah_dists <- mahalanobis(dscags, means, cov(dscags))
  mah_max <- sort(mah_dists, decreasing = TRUE)[1:n]
  choices$maha.choice[i] <- list(which(mah_dists %in% mah_max))
}

accuracy <- data.frame(Euclidean = numeric(K), Mahalanobis = numeric(K), LDA = numeric(K), QDA = numeric(K), Logistic = numeric(K), KNN = numeric(K), Random.Forest = numeric(K))

for(set in 1:K){
  correct <- choices$correct.choice[[set]]
  accuracy$Euclidean[set] <- mean(choices$eu.choice[[set]] %in% correct)
  accuracy$Mahalanobis[set] <- mean(choices$maha.choice[[set]] %in% correct)
  accuracy$LDA[set] <- mean(choices$lda.choice[[set]] %in% correct)
  accuracy$QDA[set] <- mean(choices$qda.choice[[set]] %in% correct)
  accuracy$Logistic[set] <- mean(choices$logit.choice[[set]] %in% correct)
  accuracy$KNN[set] <- mean(choices$knn.choice[[set]] %in% correct)
  accuracy$Random.Forest[set] <- mean(choices$rf.choice[[set]] %in% correct)
}   

colMeans(accuracy)

###NEED TO REWORK
```

